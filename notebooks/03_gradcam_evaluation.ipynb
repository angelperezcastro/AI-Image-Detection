{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ae0b48",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- 03_gradcam_evaluation.ipynb ---\n",
    "\n",
    "# ✅ 1. Imports\n",
    "import torch\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "from src.model import build_model\n",
    "from src.gradcam_viz import generate_gradcam\n",
    "from src.evaluate import evaluate_model\n",
    "\n",
    "# ✅ 2. Cargar configuración\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ✅ 3. Cargar modelo entrenado\n",
    "model = build_model(config[\"model\"])\n",
    "checkpoint = torch.load(config[\"paths\"][\"best_model_path\"], map_location=device)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# ✅ 4. Evaluar en el conjunto de validación\n",
    "metrics = evaluate_model(model, config[\"paths\"][\"val_dir\"], device=device)\n",
    "print(\"Resultados de evaluación:\", metrics)\n",
    "\n",
    "# ✅ 5. Visualizar Grad-CAM\n",
    "image_path = config[\"samples\"][\"gradcam_example\"]\n",
    "output_path = \"results/figures/gradcam_example.png\"\n",
    "\n",
    "generate_gradcam(\n",
    "    model=model,\n",
    "    image_path=image_path,\n",
    "    output_path=output_path,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# ✅ 6. Mostrar resultado\n",
    "img = plt.imread(output_path)\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Visualización Grad-CAM\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
